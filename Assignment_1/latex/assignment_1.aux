\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Theory}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}What is \textit  {concept learning}? + explain with an example}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}What is function approximation and why do we need them?}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}What is inductive bias in the context of machine learning, and why is it so important? Decision tree learning and the candidate elimination algorithm are two different learning algorithms. What can you say about the inductive bias for each of them?}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}What is \textit  {overfitting}, and how does it differ from \textit  {underfitting}? Briefly explain what a validation set is. How can cross-validation be used to mitigate overfitting?}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}See the problems in seperate pdf}{2}\protected@file@percent }
\newlabel{list:first}{{1}{2}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Sample Python code -- Fibonacci sequence calculated analytically.}{2}\protected@file@percent }
\newlabel{list:second}{{2}{3}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}Sample Bash code.}{3}\protected@file@percent }
