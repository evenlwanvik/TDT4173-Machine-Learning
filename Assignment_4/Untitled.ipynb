{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDT4173: Machine Learning and Case-Based Reasoning\n",
    "\n",
    "## Assignment 4 - Even L. Wanvik - 07.10.2019\n",
    "\n",
    "### 1 Theory [1.5 points]\n",
    "\n",
    "#### 1.1 [0.2 points] What characterises case-based reasoning (CBR) methods? How are they different from other machine learning approaches?\n",
    "\n",
    "The main characteristic of a case-based reasoning method is that it stores previous experiences rather than creating distinct logical rules or neural/bayesian networks. Instead of inductive reasoning, it finds a solution based on transductive reasoning, as it maps the retrieved a previously observed case, supposedly the most similar to our current case, to fit our current target/case.\n",
    "\n",
    "Compared to other rule-inducing algorithms that generalize \"prematurely\" from the training data, a CBR method performs a *lazy generalization*, where it delays the generalization of its cases until testing time. CBR method tends to perform better for more comprehensive and complex domains in which it is effectively impossible to generalize every outcome.\n",
    "\n",
    "#### 1.2 [0.4 points] Discuss (some of) the ways in which cognitive science has influenced CBR.\n",
    "\n",
    "CBR is related to research within analogical reasoning, which is an area of research in cognitive science. CBR utilizes the cognitive science of how humans derive their actions or conclusions is from finding analogies the most similar previous experiences stored as episodic memory. Like humans learn by remembering new experiences for future use, CBR stores new cases. \n",
    "\n",
    "#### 1.3 [0.3 points] Methods to evaluate the degree of similarity between two cases are essential in CBR. What is the difference between surface similarity and structural similarity? Give some examples for each approach.\n",
    "\n",
    "<img style=\"float: left;\" src=\"images/KnnClassification.png\" style=\"width:50px;\"> \n",
    "Surface similarity is a more high-level approach, where attribute-value vectors are compared both locally (attribute-wise) and globally (weighted average of local similarities). The retrieved case(s) are the k-most similar to our target case/problem in a \"k-nearest neighbor\" fashion, also referred to as k-NN. The image to the left illustrates a simple example of k-NN classification; the green dot is our target case, and the red triangles and blue squares are stored classes of cases. If k is a threshold up until the solid line, our case is classified as a red triangle. If up until the dashed line, our target case is most similar to the square case, etc. Another approach for surface similarity is using a k-d tree, in which the retrieval time is reduced by containing cases similar to each other in groups according to a similarity measure. \n",
    "\n",
    "A structural similarity measure is a more comprehensive method which evaluates the domain and structure of the cases, rather than having a simple attribute-value vector attached to each case. The best example of structural similarity would be in object-oriented programming, where cases are represented by objects. Objects belong to classes and can be classes themselves, hence the complexity. Objects that are close to each other in the \"class hierarchy\" are most likely more similar than objects farther apart. A surface similarity search will at most have an O(n) complexity, n being the number of cases. A structural similarity algorithm, on the other hand, has to measure the similarities between objects in class hierarchies and between the classes themselves, which is much more computationally expensive. One proposed method to alleviate the computational cost is to combine surface and structural similarity in a two-stage retrieval process. Other than the object-oriented approach, we have spreading activation methods, in which an interconnected network of nodes captures \"activation\" (weights) spread from the target, and the most similar response is caught.\n",
    "\n",
    "#### 1.4 [0.3 points] Explain how the similarity between cases can be measured when cases are made up of attributes with different data types. Give an example of how this can be done.\n",
    "\n",
    "* We should be able to use the *euclidean distance* provided that:\n",
    "    * the data can be approximated by a normal distribution, we can re-scale it into a real value between 0 (mean) and 1 (standard deviation). \n",
    "    * We can re-code the textual/categorical elements, e.g. \"male\"/\"female\". \n",
    "    \n",
    "SPØR OM FLERE!\n",
    "\n",
    "#### 1.5  [0.3 points] What are knowledge containers in the context of CBR? Give a brief explanation of the different containers.\n",
    "\n",
    "There are four so-called knowledge containers that are in play when using a CBR approach, namely *vocabulary*, *case base*, *similarity*, and *adaptation*. The initial CBR could just be a large collection of known cases. As the system evolves, knowledge can be fransferred from *case base* to similarity or adaptation containers and maybe even a revised vocabulary. The interplay between the containers is an important part of the systems ability to adapt and evolve.\n",
    "\n",
    "The case-base container holds all pervious experiences as a problem-solution pair. Similarity container is somewhat of a guide of to which case that is most similar to the current problem. Vocabulary specifies the structure and language used to represent, gather and organize the cases. Adaptation modifies the retrieved case solution to fit our target problem.\n",
    "\n",
    "\n",
    "\n",
    "### 2 Practical [1.5 points]\n",
    "\n",
    "\n",
    "#### 2.1 Case Modelling [0.5 points]\n",
    "\n",
    "##### a) Create a new concept called patient, which will be used as the basis for the rest of this assignment.\n",
    "##### b) Create 4-6 relevant attributes for the patient concept, including name, weight, and sleep quality.\n",
    "I chose to use:\n",
    "* name – a purely descriptive string.\n",
    "* weight_m – a float value representing the weight of the patient in kilograms.\n",
    "* sleep_quality – a symbol type with at least low, medium, and high as allowed.\n",
    "* sex - a symbol with either F (female) or male (male)\n",
    "* height_m - a float value representing the heigh of the patient in meters.\n",
    "* age - a integer value representing the age of the patient.\n",
    "\n",
    "##### c) Create ten or more instances of the patient concept, for each instance you must fill out all of the attributes.\n",
    "\n",
    "##### d) Include a screenshot of 2-3 of the instances in your report.\n",
    "\n",
    "\n",
    "<img src=\"images/patient0.png\" style=\"width:800px;\">\n",
    "<img src=\"images/patient1.png\" style=\"width:800px;\"> \n",
    "<img src=\"images/patient2.png\" style=\"width:800px;\"> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2.2 Case Retrieval [1 point]\n",
    "\n",
    "##### e) [0.3 points] Create a global similarity measure for the patient concept. It should ignore the name attribute. Create a few different similarity measures for the weight attribute, including one where the similarity is 1 for an exact match, and otherwise decreasing linearly towards 0 the further away the weight values are apart. Select the other attribute similarity modes and comparison functions as you see fit\n",
    "\n",
    "<img src=\"images/2_2e.png\" style=\"width:800px;\"> \n",
    "\n",
    "\n",
    "##### f) [0.3 points] Perform at least five different retrieval queries. Explain the returned similarity scores for the top 3 results for one of your most interesting queries. Include a screenshot of each retrieval result in your report. Were there any strange or unexpected results? Explain your answer.\n",
    "\n",
    "The similarity measures can be described as the following:\n",
    "* **Age:** A fourth-degree polynomial attenuation ranging from -100 to +100. Its global similarity measure has a weight of 0.7.\n",
    "* **Height:** A linear custom function ranging from -50 to + 50 meters with a peak at 0 with the value 0.7. The global similarity measure is 1.0 since I used 0.7 as the max weight in the local similarity measure to test it.\n",
    "* **Name:** has no local similarity measure and a weight of 0.0 in the global similarity.\n",
    "* **Sex:** A unit matrix with 1.0 on the diagonal and 0 otherwise. The global similarity measure has a weight of 0.5.\n",
    "* **Sleep quality:** A symmetric matrix with 0.7 on the diagonal and 0.4 everywhere else except for the edges.\n",
    "* **Weight:** created one of each function, chose to stick with a fifth-degree polynomial ranging from -150 to 150. The global similarity measure has a weight of 0.8.\n",
    "\n",
    "Underneath are the three cases which got the highest similarity results:\n",
    "\n",
    "<img style=\"float: left;\" src=\"images/Adolf_query.png\">\n",
    "<img style=\"float: left;\"  src=\"images/Adolf_SM.png\"> <br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "<img style=\"float: left;\"  src=\"images/Bernt_query.png\"> \n",
    "<img style=\"float: left;\" src=\"images/Bernt_SM.png\"> <br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "<img style=\"float: left;\" src=\"images/Helen_query.png\"> \n",
    "<img style=\"float: left;\" src=\"images/Helen_SM.png\"> <br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "I did not have any super strange retrieval results, as I chose the similarity measures with a bit intuition, but of course, they could have been more thought through. I do, however, have a few thoughts about the results, and how I could have improved them. The most noticeable error is the age similarity; it should not have been a higher weight for patients who are of the same age. If we had had an idea about what we are trying to classify, it would be much easier to choose the similarity measures and their weights. For instance, if the illness is highly correlated with age, like chronic back pain, the age similarity should have a much higher toll than certain other measurements, such as the patient's height. A cross-sex similarity should also have been created, as most illnesses are not that sex-dependent.\n",
    "\n",
    "\n",
    "##### f) [0.4 points] The CBR cycle include retrieve, reuse, revise, and retain. Come up with one or more problems that use the patient concept. Briefly explain how each step in the CBR cycle can be executed with the help of myCBR.\n",
    "\n",
    "* Diagnosis\n",
    "* Treatment\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
