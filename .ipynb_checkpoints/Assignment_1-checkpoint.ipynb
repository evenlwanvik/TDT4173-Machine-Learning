{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDT4173 Machine Learning - Assignment 1\n",
    "\n",
    "## Theory\n",
    "\n",
    "___\n",
    "\n",
    "###### 1. **[0.1 points]** What is concept learning? + explain with an example\n",
    "\n",
    "> The problem of searching through a predefined space of potential hyptheses for the hypothesis that best fits the training examples'' - Tom Michell\n",
    "\n",
    "When a human being is learning something, much of it is based on generalized concepts gained from past experiences. For instance, if a human were to identify if a certain type of car, we differentiate the betwen the cars based on a set of features. This bundle of features can be called a concept. \n",
    "\n",
    "Similarly, we can provide a machine with a training sample of a given signal or dataset from which it can learn the correct concepts needed to identify wether new data or objects belong to a specific category. These generalized concepts is commonly referred to as a hypothesis. \n",
    "\n",
    "**An example:** Let's say we want to identify reptiles in a dataset containing all types of animals. We extract a random subset for training the model, in which we have a set of features; *scales, coldBlooded, legs, eggLaying*. To start with we have a random sample from the training set as the starting hypothesis. This hypothesis will constantly evolve as we challenge the current hypothesis against the training data. This will go on until the hypothesis remains unchanged, and we have the best possible concept needed to differentiate reptiles from other animals.\n",
    "___\n",
    "\n",
    "###### 2. **[0.1 points]** What is function approximation and why do we need them?\n",
    "\n",
    "Function approximation is the process of adjusting the given model, or function, to most likely represent the true target function. As for the evolution of hypothesis explained in the previous question, we need these function approximations to actively determine the vital parameters and their weight.\n",
    "\n",
    "3. **[0.4 points]** What is inductive bias in the context of machine learning, and why is it so important? Decision tree learning and the candidate elimination algorithm are two different learning algorithms. What can you say about the inductive bias for each of them?\n",
    "\n",
    "> An inductive bias of a learner is the set of additional assumptions sufficient to justify its inductive inerference as deductive inference'' - Tom Michell\n",
    "\n",
    "Inductive bias is a set of assumptions used to predict a given output if it encounters a new input. Without this bias, the algorithm wouldn't have learned anything except how to handle distinct key-value pairs, for instance, if a car encounters a cat, but it is trained to avoid dogs, it might not with high enough certainty know what to do. \n",
    "\n",
    "When using a decision tree learning algorithm, we use a bias called a search bias which is greedy and keeps the most relevant searches higher up in the tree to make it as short as possible. The candidate elimination algorithm, however, uses a representational bias because it cannot represent all hypothesis. So instead of greedily choosing which part of the whole hypothesis space to search, it assumes that the solution to the problem can be expressed as a conjunction of concepts.\n",
    "\n",
    "___\n",
    "\n",
    "###### 4. **[0.3 points]**  What is overfitting, and how does it differ from *underfitting*? Briefly explain what a validation set is. How can cross-validation be used to mitigate overfitting?\n",
    "\n",
    "Overfitting refers to a model that models the training data too well. Overfitting occurs when the model learns both the valuable data and noise in the training data, which will be applied to new datasets and negatively impact the model's ability to generalize. Underfitting, on the other hand, refers to a model that neither has learned the training data nor infer from new data.\n",
    "\n",
    "The validation set makes up about 20 percent of the bulk of data used (training set ~60%) when training the model. The validation set is used for choosing the best of the models found by the training data and optimizing it. During the validation phase, overfitting is checked and avoided.\n",
    "\n",
    "Cross-validation uses the initial training data to generate *n* different mini train-test subsets and used to generate *n* different hypothesis, which allows us to tune the hyperparameters with only our original training set. This way of repeating the expoeriment multiple times gives a more accurate indication of how well the model generalizes to unseen data. Cross-validation does not prevent overfitting in itself, but it may help in identifying a case of overfitting.\n",
    "\n",
    "___\n",
    "\n",
    "###### 2. **[0.6 points]** Apply candidate elimination (CE) algorithm on the data given below in Table 1, where {T reatmentSuccessful} is the target attribute. The tabular data given below is based on physiotherapy questionnaire results for patients having pain concerning musculoskeletal disorders and its treatment successfulness. ‘Problem Area’ indicates region of the pain, ‘Activity Level’ describes the current physical activity level of the patient, ‘Sleep Quality’ indicates the level of sleep quality of the patient and ‘Treatment Successful’ indicates whether the treatment was successful in lowering the pain or not. The task is to learn to predict the value of Treatment Successful for an arbitrary values of the questionnaires. Describe the version space, specific hypothesis and general hypothesis boundary for this task (represent the version space starting from the initial boundary sets corresponding to the most specific and most generic hypotheses. You must represent the version space when CE algorithim visits a new negative or positive sample/example). The representation for “no value is acceptable” is ‘Ø’, and “any value is acceptable” is ‘?’. Also, the hypothesis space should be restricted to include only conjunctions of the attribute values.\n",
    "\n",
    "| **Sex** | **Problem Area** | **Activity Level** | **Sleep Quality** | **STreatment Successful** |\n",
    "|---------|:----------------:|:------------------:|:-----------------:|:-------------------------:|\n",
    "| Female  |        Back      |       Medium       |       Medium      |           yes             |\n",
    "| Female  |        Neck      |       Medium       |        High       |           no              |\n",
    "| Male    |      Shoulder    |        Low         |        Low        |           yes             |\n",
    "| Male    |        Neck      |        High        |      Medium       |           yes             |\n",
    "| Female  |        Back      |       Medium       |        Low        |           yes             |\n",
    "\n",
    "The candidate-elimination algorithm computes the version space containing all (and only those) hypotheses from H that are consistent with an observed sequence of training examples. For our hypothesis space (*H*), we will start with the sets of maximally general (*G*) and maximally specific (*S*) hypotheses:\n",
    "```\n",
    "S0 = {<Ø,Ø,Ø,Ø>}\n",
    "G0 = {<?,?,?,?>}\n",
    "H0 = {<Ø,Ø,Ø;Ø>}\n",
    "```\n",
    "If we now feed our data from top to bottom of the list, the sequential hypothesis spaces becomes:\n",
    "```\n",
    "D1 = {Female, Back, Medium, Medium} + (positive)\n",
    "Positive dataset -> we need to generalize our specific hypothesis:\n",
    "S1 = {<Female,Back,Medium,Medium>}\n",
    "G1 = {<?,?,?,?>}\n",
    "H1 = {<Female,Back,Medium,Medium>}\n",
    "```\n",
    "```\n",
    "D2 = {Female, Neck, Medium, High} - (negative)\n",
    "negative dataset -> make a minimal specialization of G that are consistent with the negative sample:\n",
    "S2 = {<Female,Back,Medium,Medium>}\n",
    "G2 = {<?,Back,?,Medium>}\n",
    "H2 = {<Female,Back,Medium,Medium>}\n",
    "```\n",
    "```\n",
    "D2 = {Female, Neck, Medium, High} +\n",
    "S2 = {<Male,Shoulder,Low,Low>}\n",
    "G2 = {<?,Back,?,Medium>}\n",
    "H2 = {<Female,Back,Medium,Medium>}\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programming exercise 1\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_directory_from_path(direc):\n",
    "    \"\"\"\n",
    "    Loads directory structure with CSV files into directory\n",
    "    Parameters\n",
    "    ----------\n",
    "    direc : str\n",
    "      Path to directory to be converted to dictionary\n",
    "    Returns\n",
    "    ----------\n",
    "    ds : dictionary\n",
    "      Directory modelled as a dictionary\n",
    "    \"\"\"\n",
    "    ds = {}\n",
    "    for i in os.listdir(direc):\n",
    "    path = os.path.join(direc, i)\n",
    "    if os.path.isfile(path): continue # continue if file in root\n",
    "    ds[i] = {}\n",
    "    for j in os.listdir(path):\n",
    "        if os.path.splitext(j)[1] == '.csv': # Select only files with given extension\n",
    "            with open(os.path.join(path, j)) as data:\n",
    "                keys = j.replace('.csv','')\n",
    "                df = pd.read_csv(data)\n",
    "                print(df)\n",
    "                #variables = {'x1'}\n",
    "                #ds[i].update()\n",
    "    return ds\n",
    "\n",
    "direc = os.getcwd() + \"/dataset\" # Get current working directory\n",
    "ds = create_directory_from_path(direc)\n",
    "\n",
    "# use pseudoinverse when calculating the MSE to avoid zero in denominator\n",
    "# pinv() in numpy\n",
    "\n",
    "# 1. Implement linear regression with ordinary least squares (OLS) using the\n",
    "# closed-form solution seen in Equation 9.\n",
    "\n",
    "# Load variables\n",
    "#x = ds['regression']['train_1d_reg_data'][:,0]\n",
    "#y = ds['regression']['train_1d_reg_data'][:,0]\n",
    "\n",
    "#print(vals[:,0])\n",
    "\n",
    "# find weight that gies the OLS\n",
    "#w = np.linalg.pinv( x1.transpose().dot(x1) ).dot( x1.transpose().dot(y) )\n",
    "\n",
    "#print(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
